
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Stats &#8212; PyMC3 3.5 documentation</title>
    <link rel="stylesheet" href="../_static/semantic-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/default.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <script type="text/javascript" src="../_static/highlight.min.js"></script>
    <script type="text/javascript" src="../_static/semantic.min.js"></script>
    <link rel="shortcut icon" href="../_static/PyMC3.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<script>hljs.initHighlightingOnLoad();</script>
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">



  </head><body>
<div class="ui vertical center aligned">

    <div class="ui container">
        <div class="ui large secondary pointing menu">
            <a class="item" href="/">
                <img class="ui bottom aligned tiny image" src="https://cdn.rawgit.com/pymc-devs/pymc3/master/docs/logos/svg/PyMC3_banner.svg" />
            </a>
             <a href="../nb_tutorials/index.html" class="item">Tutorials</a> <a href="../nb_examples/index.html" class="item">Examples</a> <a href="../learn.html" class="item">Books + Videos</a> <a href="../api.html" class="item">API</a> <a href="../developer_guide.html" class="item">Developer Guide</a> <a href="../history.html" class="item">About PyMC3</a>
            
            <div class="right menu">
                <div class="item">
                    <form class="ui icon input" action="../search.html" method="get">
                        <input type="text" placeholder="Search..." name="q" />
                        <i class="search link icon"></i>
                    </form>
                </div>
                <a class="item" href="https://github.com/pymc-devs/pymc3"><i class="github blue icon large"></i></a>
            </div>
        </div>
    </div>
    
</div>

<div class="ui container" role="main">
    

    <div class="ui vertical segment">
        
  <div class="section" id="module-pymc3.stats">
<span id="stats"></span><h1>Stats<a class="headerlink" href="#module-pymc3.stats" title="Permalink to this headline">¶</a></h1>
<p>Statistical utility functions for PyMC</p>
<dl class="function">
<dt id="pymc3.stats.autocorr">
<code class="descclassname">pymc3.stats.</code><code class="descname">autocorr</code><span class="sig-paren">(</span><em>pymc3_obj</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.autocorr" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute autocorrelation using FFT for every lag for the input array
<a class="reference external" href="https://en.wikipedia.org/wiki/Autocorrelation#Efficient_computation">https://en.wikipedia.org/wiki/Autocorrelation#Efficient_computation</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Numpy array</span></dt><dd><p>An array containing MCMC samples</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>acorr: Numpy array same size as the input array</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.autocov">
<code class="descclassname">pymc3.stats.</code><code class="descname">autocov</code><span class="sig-paren">(</span><em>pymc3_obj</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.autocov" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute autocovariance estimates for every lag for the input array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Numpy array</span></dt><dd><p>An array containing MCMC samples</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>acov: Numpy array same size as the input array</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.waic">
<code class="descclassname">pymc3.stats.</code><code class="descname">waic</code><span class="sig-paren">(</span><em>trace</em>, <em>model=None</em>, <em>pointwise=False</em>, <em>progressbar=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.waic" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the widely available information criterion, its standard error
and the effective number of parameters of the samples in trace from model.
Read more theory here - in a paper by some of the leading authorities on
model selection - dx.doi.org/10.1111/1467-9868.00353</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>trace</strong><span class="classifier">result of MCMC run</span></dt><dd></dd>
<dt><strong>model</strong><span class="classifier">PyMC Model</span></dt><dd><p>Optional model. Default None, taken from context.</p>
</dd>
<dt><strong>pointwise: bool</strong></dt><dd><p>if True the pointwise predictive accuracy will be returned.
Default False</p>
</dd>
<dt><strong>progressbar: bool</strong></dt><dd><p>Whether or not to display a progress bar in the command line. The
bar shows the percentage of completion, the evaluation speed, and
the estimated time to completion</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>namedtuple with the following elements:</dt><dd></dd>
<dt>waic: widely available information criterion</dt><dd></dd>
<dt>waic_se: standard error of waic</dt><dd></dd>
<dt>p_waic: effective number parameters</dt><dd></dd>
<dt>var_warn: 1 if posterior variance of the log predictive</dt><dd><p>densities exceeds 0.4</p>
</dd>
<dt>waic_i: and array of the pointwise predictive accuracy, only if pointwise True</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.loo">
<code class="descclassname">pymc3.stats.</code><code class="descname">loo</code><span class="sig-paren">(</span><em>trace</em>, <em>model=None</em>, <em>pointwise=False</em>, <em>reff=None</em>, <em>progressbar=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.loo" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates leave-one-out (LOO) cross-validation for out of sample
predictive model fit, following Vehtari et al. (2015). Cross-validation is
computed using Pareto-smoothed importance sampling (PSIS).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>trace</strong><span class="classifier">result of MCMC run</span></dt><dd></dd>
<dt><strong>model</strong><span class="classifier">PyMC Model</span></dt><dd><p>Optional model. Default None, taken from context.</p>
</dd>
<dt><strong>pointwise: bool</strong></dt><dd><p>if True the pointwise predictive accuracy will be returned.
Default False</p>
</dd>
<dt><strong>reff</strong><span class="classifier">float</span></dt><dd><p>relative MCMC efficiency, <cite>effective_n / n</cite> i.e. number of effective
samples divided by the number of actual samples. Computed from trace by
default.</p>
</dd>
<dt><strong>progressbar: bool</strong></dt><dd><p>Whether or not to display a progress bar in the command line. The
bar shows the percentage of completion, the evaluation speed, and
the estimated time to completion</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>namedtuple with the following elements:</dt><dd></dd>
<dt>loo: approximated Leave-one-out cross-validation</dt><dd></dd>
<dt>loo_se: standard error of loo</dt><dd></dd>
<dt>p_loo: effective number of parameters</dt><dd></dd>
<dt>shape_warn: 1 if the estimated shape parameter of</dt><dd><p>Pareto distribution is greater than 0.7 for one or more samples</p>
</dd>
<dt>loo_i: array of pointwise predictive accuracy, only if pointwise True</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.hpd">
<code class="descclassname">pymc3.stats.</code><code class="descname">hpd</code><span class="sig-paren">(</span><em>pymc3_obj</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.hpd" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate highest posterior density (HPD) of array for given alpha. The HPD is the
minimum width Bayesian credible interval (BCI).</p>
<p>This function assumes the posterior distribution is unimodal:
it always returns one interval per variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Arguments</dt>
<dd class="field-odd"><dl class="simple">
<dt>x<span class="classifier">Numpy array</span></dt><dd><p>An array containing MCMC samples</p>
</dd>
<dt>alpha<span class="classifier">float</span></dt><dd><p>Desired probability of type I error (defaults to 0.05)</p>
</dd>
<dt>transform<span class="classifier">callable</span></dt><dd><p>Function to transform data (defaults to identity)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.quantiles">
<code class="descclassname">pymc3.stats.</code><code class="descname">quantiles</code><span class="sig-paren">(</span><em>pymc3_obj</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.quantiles" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary of requested quantiles from array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Numpy array</span></dt><dd><p>An array containing MCMC samples</p>
</dd>
<dt><strong>qlist</strong><span class="classifier">tuple or list</span></dt><dd><p>A list of desired quantiles (defaults to (2.5, 25, 50, 75, 97.5))</p>
</dd>
<dt><strong>transform</strong><span class="classifier">callable</span></dt><dd><p>Function to transform data (defaults to identity)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><cite>dictionary</cite> with the quantiles {quantile: value}</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.mc_error">
<code class="descclassname">pymc3.stats.</code><code class="descname">mc_error</code><span class="sig-paren">(</span><em>pymc3_obj</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.mc_error" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Calculates the simulation standard error, accounting for non-independent</dt><dd><p>samples. The trace is divided into batches, and the standard deviation of
the batch means is calculated.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Numpy array</span></dt><dd><p>An array containing MCMC samples</p>
</dd>
<dt><strong>batches</strong><span class="classifier">integer</span></dt><dd><p>Number of batches</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><cite>float</cite> representing the error</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.summary">
<code class="descclassname">pymc3.stats.</code><code class="descname">summary</code><span class="sig-paren">(</span><em>trace</em>, <em>varnames=None</em>, <em>transform=&lt;function &lt;lambda&gt; at 0x121084840&gt;</em>, <em>stat_funcs=None</em>, <em>extend=False</em>, <em>include_transformed=False</em>, <em>alpha=0.05</em>, <em>start=0</em>, <em>batches=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a data frame with summary statistics.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>trace</strong><span class="classifier">MultiTrace instance</span></dt><dd></dd>
<dt><strong>varnames</strong><span class="classifier">list</span></dt><dd><p>Names of variables to include in summary</p>
</dd>
<dt><strong>transform</strong><span class="classifier">callable</span></dt><dd><p>Function to transform data (defaults to identity)</p>
</dd>
<dt><strong>stat_funcs</strong><span class="classifier">None or list</span></dt><dd><p>A list of functions used to calculate statistics. By default,
the mean, standard deviation, simulation standard error, and
highest posterior density intervals are included.</p>
<p>The functions will be given one argument, the samples for a
variable as a 2 dimensional array, where the first axis
corresponds to sampling iterations and the second axis
represents the flattened variable (e.g., x__0, x__1,…). Each
function should return either</p>
<ol class="arabic simple">
<li><p>A <cite>pandas.Series</cite> instance containing the result of
calculating the statistic along the first axis. The name
attribute will be taken as the name of the statistic.</p></li>
<li><p>A <cite>pandas.DataFrame</cite> where each column contains the
result of calculating the statistic along the first axis.
The column names will be taken as the names of the
statistics.</p></li>
</ol>
</dd>
<dt><strong>extend</strong><span class="classifier">boolean</span></dt><dd><p>If True, use the statistics returned by <cite>stat_funcs</cite> in
addition to, rather than in place of, the default statistics.
This is only meaningful when <cite>stat_funcs</cite> is not None.</p>
</dd>
<dt><strong>include_transformed</strong><span class="classifier">bool</span></dt><dd><p>Flag for reporting automatically transformed variables in addition
to original variables (defaults to False).</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float</span></dt><dd><p>The alpha level for generating posterior intervals. Defaults
to 0.05. This is only meaningful when <cite>stat_funcs</cite> is None.</p>
</dd>
<dt><strong>start</strong><span class="classifier">int</span></dt><dd><p>The starting index from which to summarize (each) chain. Defaults
to zero.</p>
</dd>
<dt><strong>batches</strong><span class="classifier">None or int</span></dt><dd><p>Batch size for calculating standard deviation for non-independent
samples. Defaults to the smaller of 100 or the number of samples.
This is only meaningful when <cite>stat_funcs</cite> is None.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><cite>pandas.DataFrame</cite> with summary statistics for each variable Defaults one</dt><dd></dd>
<dt>are: <cite>mean</cite>, <cite>sd</cite>, <cite>mc_error</cite>, <cite>hpd_2.5</cite>, <cite>hpd_97.5</cite>, <cite>n_eff</cite> and <cite>Rhat</cite>.</dt><dd></dd>
<dt>Last two are only computed for traces with 2 or more chains.</dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">pm</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">trace</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">])</span>
           <span class="n">mean</span>        <span class="n">sd</span>  <span class="n">mc_error</span>     <span class="n">hpd_5</span>    <span class="n">hpd_95</span>
<span class="n">mu__0</span>  <span class="mf">0.106897</span>  <span class="mf">0.066473</span>  <span class="mf">0.001818</span> <span class="o">-</span><span class="mf">0.020612</span>  <span class="mf">0.231626</span>
<span class="n">mu__1</span> <span class="o">-</span><span class="mf">0.046597</span>  <span class="mf">0.067513</span>  <span class="mf">0.002048</span> <span class="o">-</span><span class="mf">0.174753</span>  <span class="mf">0.081924</span>

          <span class="n">n_eff</span>      <span class="n">Rhat</span>
<span class="n">mu__0</span>     <span class="mf">487.0</span>   <span class="mf">1.00001</span>
<span class="n">mu__1</span>     <span class="mf">379.0</span>   <span class="mf">1.00203</span>
</pre></div>
</div>
<p>Other statistics can be calculated by passing a list of functions.</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">trace_sd</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sd&#39;</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">trace_quantiles</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">quantiles</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">95</span><span class="p">]))</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">],</span> <span class="n">stat_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">trace_sd</span><span class="p">,</span> <span class="n">trace_quantiles</span><span class="p">])</span>
             <span class="n">sd</span>         <span class="mi">5</span>        <span class="mi">50</span>        <span class="mi">95</span>
<span class="n">mu__0</span>  <span class="mf">0.066473</span>  <span class="mf">0.000312</span>  <span class="mf">0.105039</span>  <span class="mf">0.214242</span>
<span class="n">mu__1</span>  <span class="mf">0.067513</span> <span class="o">-</span><span class="mf">0.159097</span> <span class="o">-</span><span class="mf">0.045637</span>  <span class="mf">0.062912</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.compare">
<code class="descclassname">pymc3.stats.</code><code class="descname">compare</code><span class="sig-paren">(</span><em>model_dict</em>, <em>ic='WAIC'</em>, <em>method='stacking'</em>, <em>b_samples=1000</em>, <em>alpha=1</em>, <em>seed=None</em>, <em>round_to=2</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.compare" title="Permalink to this definition">¶</a></dt>
<dd><p>Compare models based on the widely available information criterion (WAIC)
or leave-one-out (LOO) cross-validation.
Read more theory here - in a paper by some of the leading authorities on
model selection - dx.doi.org/10.1111/1467-9868.00353</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>model_dict</strong><span class="classifier">dictionary of PyMC3 traces indexed by corresponding model</span></dt><dd></dd>
<dt><strong>ic</strong><span class="classifier">string</span></dt><dd><p>Information Criterion (WAIC or LOO) used to compare models.
Default WAIC.</p>
</dd>
<dt><strong>method</strong><span class="classifier">str</span></dt><dd><p>Method used to estimate the weights for each model. Available options
are:</p>
<blockquote>
<div><ul class="simple">
<li><p>‘stacking’ : (default) stacking of predictive distributions.</p></li>
<li><dl class="simple">
<dt>‘BB-pseudo-BMA’<span class="classifier">pseudo-Bayesian Model averaging using Akaike-type</span></dt><dd><p>weighting. The weights are stabilized using the Bayesian bootstrap</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘pseudo-BMA’: pseudo-Bayesian Model averaging using Akaike-type</dt><dd><p>weighting, without Bootstrap stabilization (not recommended)</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>For more information read <a class="reference external" href="https://arxiv.org/abs/1704.02030">https://arxiv.org/abs/1704.02030</a></p>
</dd>
<dt><strong>b_samples: int</strong></dt><dd><p>Number of samples taken by the Bayesian bootstrap estimation. Only
useful when method = ‘BB-pseudo-BMA’.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float</span></dt><dd><p>The shape parameter in the Dirichlet distribution used for the
Bayesian bootstrap. Only useful when method = ‘BB-pseudo-BMA’. When
alpha=1 (default), the distribution is uniform on the simplex. A
smaller alpha will keeps the final weights more away from 0 and 1.</p>
</dd>
<dt><strong>seed</strong><span class="classifier">int or np.random.RandomState instance</span></dt><dd><p>If int or RandomState, use it for seeding Bayesian bootstrap. Only
useful when method = ‘BB-pseudo-BMA’. Default None the global
np.random state is used.</p>
</dd>
<dt><strong>round_to</strong><span class="classifier">int</span></dt><dd><p>Number of decimals used to round results (default 2).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A DataFrame, ordered from lowest to highest IC. The index reflects</dt><dd></dd>
<dt>the order in which the models are passed to this function. The columns are:</dt><dd></dd>
<dt><strong>IC</strong><span class="classifier">Information Criteria (WAIC or LOO).</span></dt><dd><p>Smaller IC indicates higher out-of-sample predictive fit (“better” model).
Default WAIC.</p>
</dd>
<dt><strong>pIC</strong><span class="classifier">Estimated effective number of parameters.</span></dt><dd></dd>
<dt><strong>dIC</strong><span class="classifier">Relative difference between each IC (WAIC or LOO)</span></dt><dd></dd>
<dt>and the lowest IC (WAIC or LOO).</dt><dd><p>It’s always 0 for the top-ranked model.</p>
</dd>
<dt>weight: Relative weight for each model.</dt><dd><p>This can be loosely interpreted as the probability of each model
(among the compared model) given the data. By default the uncertainty
in the weights estimation is considered using Bayesian bootstrap.</p>
</dd>
<dt><strong>SE</strong><span class="classifier">Standard error of the IC estimate.</span></dt><dd><p>If method = BB-pseudo-BMA these values are estimated using Bayesian
bootstrap.</p>
</dd>
<dt><strong>dSE</strong><span class="classifier">Standard error of the difference in IC between each model and</span></dt><dd></dd>
<dt>the top-ranked model.</dt><dd><p>It’s always 0 for the top-ranked model.</p>
</dd>
<dt><strong>warning</strong><span class="classifier">A value of 1 indicates that the computation of the IC may not be</span></dt><dd><p>reliable. Details see the related warning message in pm.waic and pm.loo</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.bfmi">
<code class="descclassname">pymc3.stats.</code><code class="descname">bfmi</code><span class="sig-paren">(</span><em>trace</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.bfmi" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the estimated Bayesian fraction of missing information (BFMI).</p>
<p>BFMI quantifies how well momentum resampling matches the marginal energy
distribution.  For more information on BFMI, see
<a class="reference external" href="https://arxiv.org/pdf/1604.00695.pdf">https://arxiv.org/pdf/1604.00695.pdf</a>.  The current advice is that values
smaller than 0.2 indicate poor sampling.  However, this threshold is
provisional and may change.  See
<a class="reference external" href="http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html">http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html</a>
for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>trace</strong><span class="classifier">result of an HMC/NUTS run, must contain energy information</span></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>z</strong><span class="classifier">float</span></dt><dd><p>The Bayesian fraction of missing information of the model and trace.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="pymc3.stats.r2_score">
<code class="descclassname">pymc3.stats.</code><code class="descname">r2_score</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em>, <em>round_to=2</em><span class="sig-paren">)</span><a class="headerlink" href="#pymc3.stats.r2_score" title="Permalink to this definition">¶</a></dt>
<dd><p>R-squared for Bayesian regression models. Only valid for linear models.
<a class="reference external" href="http://www.stat.columbia.edu/%7Egelman/research/unpublished/bayes_R2.pdf">http://www.stat.columbia.edu/%7Egelman/research/unpublished/bayes_R2.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true:</strong><span class="classifier">array-like of shape = (n_samples) or (n_samples, n_outputs)</span></dt><dd><p>Ground truth (correct) target values.</p>
</dd>
<dt><strong>y_pred</strong><span class="classifier">array-like of shape = (n_samples) or (n_samples, n_outputs)</span></dt><dd><p>Estimated target values.</p>
</dd>
<dt><strong>round_to</strong><span class="classifier">int</span></dt><dd><p>Number of decimals used to round results (default 2).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><cite>namedtuple</cite> with the following elements:</dt><dd></dd>
<dt>R2_median: median of the Bayesian R2</dt><dd></dd>
<dt>R2_mean: mean of the Bayesian R2</dt><dd></dd>
<dt>R2_std: standard deviation of the Bayesian R2</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>


    </div>
</div>
<div class="ui vertical footer segment">
    <div class="ui center aligned container">
        <a href="https://github.com/pymc-devs/pymc3"><i class="github icon large"></i></a>
        <a href="https://twitter.com/pymc_devs"><i class="twitter icon large"></i></a>
        <a href="https://discourse.pymc.io/"><i class="discourse icon large"></i></a>
    </div>
    <div class="ui center aligned container">
        <p>
            &copy; Copyright 2018, The PyMC Development Team.
        </p>
        <p>
            Created using <a href="https://sphinx-doc.org/">Sphinx</a> 2.0.1.<br />
        </p>
    </div>
</div>
  </body>
</html>